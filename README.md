# fake-news-detection-ml

[![Cookiecutter Data Science logo](https://img.shields.io/badge/CCDS-Project%20template-328F97?logo=cookiecutter "Cookiecutter Data Science")](https://cookiecutter-data-science.drivendata.org/)

This repository is a term paper for the Introduction to Machine Learning course at UJEP. It implements a complete data science pipeline to predict the reliability of news articles based on their content.

---

## ğŸš€ Getting Started

This project uses [uv](https://github.com/astral-sh/uv) for managing environments and dependencies. You can also use `pip` if preferred.

---

### âœ… Setup with `uv` (recommended)

> Make sure you have Python 3.12 and [uv](https://github.com/astral-sh/uv) installed.

```bash
# Create virtual environment
make create_environment

# Activate the environment
source .venv/bin/activate  # macOS/Linux
# OR
.\\.venv\\Scripts\\activate  # Windows

# Install dependencies
make requirements

# Run the full pipeline (download, preprocess, train, predict, report)
make pipeline
```

## ğŸ Setup with pip (alternative)

1. Create and activate a virtual environment:

    ```bash
    python3 -m venv .venv
    source .venv/bin/activate  # macOS/Linux
    # OR
    .\\.venv\\Scripts\\activate  # Windows
    ```

2. Install dependencies:

    ```bash
    pip install -r requirements.txt
    ```

3. Run the pipeline step-by-step:

    ```bash
    # Download raw data
    python detection/dataset.py download

    # Preprocess data
    python notebooks/1.0-data-cleaning-and-feature-creation.ipynb

    # Train model
    python train.py

    # Predict on test data
    python predict.py

    # Generate publication report
    python notebooks/4.0-publication.ipynb
    ```

## ğŸ›  Makefile Commands

```bash
make help          # List all available make commands
make create_environment
make requirements
make data
make preprocess
make train
make predict
make publish
make pipeline      # Run the full end-to-end pipeline
make clean
```

## ğŸ“ Project Organization

```txt
â”œâ”€â”€ LICENSE            <- Open-source license
â”œâ”€â”€ Makefile           <- Makefile with convenience commands like `make data` or `make train`
â”œâ”€â”€ README.md          <- The top-level README for developers using this project.
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ external       <- Data from third party sources.
â”‚   â”œâ”€â”€ interim        <- Intermediate data that has been transformed.
â”‚   â”œâ”€â”€ processed      <- The final, canonical data sets for modeling.
â”‚   â””â”€â”€ raw            <- The original, immutable data dump.
â”‚
â”œâ”€â”€ docs               <- A default mkdocs project; see www.mkdocs.org for details
â”‚
â”œâ”€â”€ models             <- Trained and serialized models, model predictions, or model summaries
â”‚   â”œâ”€â”€ predictions
â”‚   â””â”€â”€ trained
â”œâ”€â”€ notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),
â”‚                         the creator's initials, and a short `-` delimited description, e.g.
â”‚                         `1.0-initial-data-exploration`.
â”‚   â”œâ”€â”€ 0.1-mz-initial-eda.ipynb
â”‚   â”œâ”€â”€ 1.1-mz-data-cleaning-and-feature-creation.ipynb
â”‚   â”œâ”€â”€ 2.1-mz-visualization.ipynb
â”‚   â”œâ”€â”€ 3.1-mz-modeling.ipynb
â”‚   â””â”€â”€ 4.1-mz-publication.ipynb
â”œâ”€â”€ pyproject.toml     <- Project configuration file with package metadata
â”‚
â”œâ”€â”€ reports            <- Generated analysis as HTML, PDF, LaTeX, etc.
â”‚   â””â”€â”€ figures        <- Generated graphics and figures to be used in reporting
â”‚
â”œâ”€â”€ requirements.txt   <- The requirements file for reproducing the analysis environment
â”‚
â”œâ”€â”€ uv.lock
â”‚
â””â”€â”€ src          <- Source code for use in this project
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ config.py               <- Project-wide configuration and constants
    â”œâ”€â”€ dataset.py              <- Scripts to download or generate data
    â”œâ”€â”€ modeling/
    â”‚   â”œâ”€â”€ __init__.py         
    |   â”œâ”€â”€ modeling.py
    â”‚   â”œâ”€â”€ train.py            <- Train models
    â””   â””â”€â”€ predict.py          <- Run model inference
```

## ğŸ““ Notebooks Overview

| Notebook                              | Purpose                              |
|---------------------------------------|--------------------------------------|
|1.0-data-cleaning-and-feature-creation | Preprocess raw data                  |
|2.0-visualizations                     | Visual EDA (class dist, text length) |
|3.0-modeling                           | Run model training                   |
|4.0-publication                        | Generate prediction summaries        |

## âœ… Reproducibility

This project is structured using the Cookiecutter Data Science template to ensure clean organization and reproducible results.

## ğŸ“„ License

MIT License. See `LICENSE`.
